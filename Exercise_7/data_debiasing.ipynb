{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folktables import ACSDataSource, BasicProblem, generate_categories\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import  pearsonr\n",
    "import scipy\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    sns.set()\n",
    "except:\n",
    "    print(\"Run without Seaborn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load and Preprocess the data\n",
    "We are going to work with the [Folktables](https://github.com/socialfoundations/folktables#quick-start-examples) dataset (*you have already worked with it*).\n",
    "\n",
    "1. As last week, we are still predicting the *Total person's income*  (I've digitized  it in  `target_transform=lambda x: x > 25000`).\n",
    "2. Today, we are going to implement two methods for data debiasing: [Fair PCA](https://deepai.org/publication/efficient-fair-pca-for-fair-representation-learning) and [A Geometric Solution to Fair Representations](https://dl.acm.org/doi/10.1145/3375627.3375864).\n",
    "3. We are going to evaluate the performance on two sensitive features: `SEX` and `RAC1P` (we will consider only *Whites* and *African-Americans*)\n",
    "4. I updated the filtering method `adult_filter` to keep the specified groups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "acs_data = data_source.get_data(states=[\"CA\"], download=True)\n",
    "\n",
    "\n",
    "def adult_filter(data):\n",
    "    \"\"\"Mimic the filters in place for Adult data.\n",
    "    Adult documentation notes: Extraction was done by Barry Becker from\n",
    "    the 1994 Census database. A set of reasonably clean records was extracted\n",
    "    using the following conditions:\n",
    "    ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))\n",
    "    \"\"\"\n",
    "    df = data\n",
    "    df = df[df['AGEP'] > 16]\n",
    "    df = df[df['PINCP'] > 100]\n",
    "    df = df[df['WKHP'] > 0]\n",
    "    df = df[df['PWGTP'] >= 1]\n",
    "    df = df[df[\"RAC1P\"] < 3] ## keep only Whites and African-Americans\n",
    "    return df\n",
    "\n",
    "\n",
    "ACSIncomeNew = BasicProblem(\n",
    "    features=[\n",
    "        'AGEP',\n",
    "        'COW',\n",
    "        'SCHL',\n",
    "        'MAR',\n",
    "        'RELP',\n",
    "        'WKHP',\n",
    "        'PWGTP',\n",
    "        'SEX',\n",
    "        'RAC1P',\n",
    "    ],\n",
    "    target='PINCP',\n",
    "    target_transform=lambda x: x > 25000,    \n",
    "    group=['SEX', 'RAC1P'],\n",
    "    preprocess=adult_filter,\n",
    "    postprocess=lambda x: np.nan_to_num(x, -1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>WKHP</th>\n",
       "      <th>PWGTP</th>\n",
       "      <th>COW_Employee of a private for-profit company or business, or of an individual, for wages, salary, or commissions</th>\n",
       "      <th>COW_Employee of a private not-for-profit, tax-exempt, or charitable organization</th>\n",
       "      <th>COW_Federal government employee</th>\n",
       "      <th>COW_Local government employee (city, county, etc.)</th>\n",
       "      <th>COW_Self-employed in own incorporated business, professional practice or farm</th>\n",
       "      <th>COW_Self-employed in own not incorporated business, professional practice, or farm</th>\n",
       "      <th>COW_State government employee</th>\n",
       "      <th>...</th>\n",
       "      <th>RELP_Parent-in-law</th>\n",
       "      <th>RELP_Reference person</th>\n",
       "      <th>RELP_Roomer or boarder</th>\n",
       "      <th>RELP_Son-in-law or daughter-in-law</th>\n",
       "      <th>RELP_Stepson or stepdaughter</th>\n",
       "      <th>RELP_Unmarried partner</th>\n",
       "      <th>SEX_Female</th>\n",
       "      <th>SEX_Male</th>\n",
       "      <th>RAC1P_Black or African American alone</th>\n",
       "      <th>RAC1P_White alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGEP  WKHP  PWGTP  \\\n",
       "0  21.0  20.0   52.0   \n",
       "1  65.0   8.0   33.0   \n",
       "2  33.0  40.0   53.0   \n",
       "3  18.0  18.0  106.0   \n",
       "4  27.0  50.0   23.0   \n",
       "\n",
       "   COW_Employee of a private for-profit company or business, or of an individual, for wages, salary, or commissions  \\\n",
       "0                                                0.0                                                                  \n",
       "1                                                0.0                                                                  \n",
       "2                                                1.0                                                                  \n",
       "3                                                0.0                                                                  \n",
       "4                                                0.0                                                                  \n",
       "\n",
       "   COW_Employee of a private not-for-profit, tax-exempt, or charitable organization  \\\n",
       "0                                                0.0                                  \n",
       "1                                                1.0                                  \n",
       "2                                                0.0                                  \n",
       "3                                                1.0                                  \n",
       "4                                                0.0                                  \n",
       "\n",
       "   COW_Federal government employee  \\\n",
       "0                              0.0   \n",
       "1                              0.0   \n",
       "2                              0.0   \n",
       "3                              0.0   \n",
       "4                              1.0   \n",
       "\n",
       "   COW_Local government employee (city, county, etc.)  \\\n",
       "0                                                0.0    \n",
       "1                                                0.0    \n",
       "2                                                0.0    \n",
       "3                                                0.0    \n",
       "4                                                0.0    \n",
       "\n",
       "   COW_Self-employed in own incorporated business, professional practice or farm  \\\n",
       "0                                                0.0                               \n",
       "1                                                0.0                               \n",
       "2                                                0.0                               \n",
       "3                                                0.0                               \n",
       "4                                                0.0                               \n",
       "\n",
       "   COW_Self-employed in own not incorporated business, professional practice, or farm  \\\n",
       "0                                                0.0                                    \n",
       "1                                                0.0                                    \n",
       "2                                                0.0                                    \n",
       "3                                                0.0                                    \n",
       "4                                                0.0                                    \n",
       "\n",
       "   COW_State government employee  ...  RELP_Parent-in-law  \\\n",
       "0                            1.0  ...                 0.0   \n",
       "1                            0.0  ...                 0.0   \n",
       "2                            0.0  ...                 0.0   \n",
       "3                            0.0  ...                 0.0   \n",
       "4                            0.0  ...                 0.0   \n",
       "\n",
       "   RELP_Reference person  RELP_Roomer or boarder  \\\n",
       "0                    0.0                     0.0   \n",
       "1                    0.0                     0.0   \n",
       "2                    0.0                     0.0   \n",
       "3                    0.0                     0.0   \n",
       "4                    0.0                     0.0   \n",
       "\n",
       "   RELP_Son-in-law or daughter-in-law  RELP_Stepson or stepdaughter  \\\n",
       "0                                 0.0                           0.0   \n",
       "1                                 0.0                           0.0   \n",
       "2                                 0.0                           0.0   \n",
       "3                                 0.0                           0.0   \n",
       "4                                 0.0                           0.0   \n",
       "\n",
       "   RELP_Unmarried partner  SEX_Female  SEX_Male  \\\n",
       "0                     0.0         0.0       1.0   \n",
       "1                     0.0         0.0       1.0   \n",
       "2                     0.0         0.0       1.0   \n",
       "3                     0.0         1.0       0.0   \n",
       "4                     0.0         0.0       1.0   \n",
       "\n",
       "   RAC1P_Black or African American alone  RAC1P_White alone  \n",
       "0                                    0.0                1.0  \n",
       "1                                    0.0                1.0  \n",
       "2                                    0.0                1.0  \n",
       "3                                    0.0                1.0  \n",
       "4                                    0.0                1.0  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "definition_df = data_source.get_definitions(download=True)\n",
    "categories = generate_categories(features=ACSIncomeNew.features, definition_df=definition_df)\n",
    "features, labels, groups = ACSIncomeNew.df_to_pandas(acs_data, categories=categories, dummies=True)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Pre-processing \n",
    "We encoded categorical using the *one-hot encoding*: \n",
    "1. For example, column `SEX` is split into two solumns `SEX_Male` and `SEX_Female`. \n",
    "2. You can argue that one of this columns is redundant (as when one attribute is equal to 1, the other is equal to 0). \n",
    "3. You can extend this line of thougth to a multicategory setting. Let's assume I have a feature with three categories *dog*, *cat* and *monkey* (which are represented using *one-hot encoding*). If both *cat* and *dog* are equal to 0, them *monkey* is equal to 1. In theory, I can drop *monkey* category without loosing any kind of information. \n",
    "4. Depending on your task, you might want to keep this columns, but today we are going to assume that those columns are *redundant*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with the protected features:\n",
      "Column ID: 54 (SEX_Female)\n",
      "Column ID: 55 (RAC1P_Black or African American alone)\n"
     ]
    }
   ],
   "source": [
    "# Drop the \"redundant\" columns\n",
    "features = features.drop([\"RAC1P_White alone\", \n",
    "                          \"SEX_Male\", \n",
    "                          \"SCHL_1 or more years of college credit, no degree\",  \n",
    "                          \"MAR_Divorced\", \n",
    "                          \"RELP_Adopted son or daughter\",\n",
    "                          'COW_Working without pay in family business or farm' ], axis = 1) \n",
    "\n",
    "print(\"Columns with the protected features:\")\n",
    "for i, f in enumerate(features.columns):\n",
    "    if (\"RAC1P\" in f) or (\"SEX\" in f):\n",
    "        print(\"Column ID: %s\" %i, \"(%s)\"%f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test, group_train, group_test = train_test_split(\n",
    "    features.values, labels.values.reshape(-1), groups, test_size=0.3, random_state=0, shuffle=True)\n",
    "\n",
    "N = 20000 ### I am subsampling because it is slow on my machine\n",
    "\n",
    "X_train = X_train[:N]\n",
    "y_train = y_train[:N]\n",
    "group_train = group_train[:N]\n",
    "X_test = X_test[:N]\n",
    "y_test = y_test[:N]\n",
    "group_test = group_test[:N]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Correlations in Data\n",
    "Let's look at the correlations in our data. For the sake of the time, we are going to assume only *linear interactions* between the features -- and we are just use **Pearson's Correlation Coefficient** (since we have one-hot encoded categorical variables, it is more or less ok to use **Pearson's Correlation** (Thought in your projects, I advice to use more appropriate measures like Cramer's V for categorical-categorical correlation etc. -- [dython](https://shakedzy.xyz/dython/modules/nominal/)).\n",
    "1. Normilize the continious features, aka first four columns.\n",
    "2. Use `scipy.stats.pearsonr` to estimate correlations in your data. This function outputs *correlation* and *p-value*. \n",
    "3. Use `seaborn.heatmap` to plot correlations (only plot correlations with the significant *p-values*)\n",
    "4. What features correlate with the protected features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X_train.shape[1]\n",
    "alpha = 0.05 ## significance level\n",
    "corrected_alpha = alpha / (n_features**2/2) # Bonferroni correction for multiple testings\n",
    "\n",
    "corr = np.zeros((n_features, n_features))\n",
    "p = np.zeros((n_features, n_features))\n",
    "\n",
    "##############################\n",
    "######### Your code here\n",
    "##############################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "### Visualise full correlarion matrix\n",
    "#########################\n",
    "#plt.figure(figsize=(15,15))\n",
    "#seaborn.heatmap(... mask= p > corrected_alpha)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "### Visualise columns of the correlation matrix that are associated only with protected features (see Lecture Slides)\n",
    "#########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Simple Logistic Regression (by droping the protected attributes)\n",
    "1. Drop the protected attributes from the training and test data\n",
    "2. Let's train a simple logistic regression (**WITHOUT** any penalty). If your model does not converge, then increase `max_iter`. \n",
    "3. Use your favourite **fairness metric** (e.g. False Positive Rate) to see how your model performs based on the protected feature (you have 2 for `SEX` and 2 groups for `RAC1P`) - use `group_test`. \n",
    "3. Use your favourite **evaluation metric** to find out how your model performed in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "##### YOUR CODE HERE\n",
    "####################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Fair Representation\n",
    "Now, we are going to implement the method from [A Geometric Solution to Fair Representations](https://dl.acm.org/doi/10.1145/3375627.3375864): we want to remove protected features from the dataset, plus, remove any existing correlations.\n",
    "1. Let's split our pre-processed `X_train` into chunks that contain only protected features (aka columns associated with `SEX` and `RAC1P`) and non-protected features.\n",
    "2. Implement a method that outputs debiased data representation:\n",
    "    1. Find the orthonormal basis spanned by the column of **protected** features  -- use `scipy.linalg.orth`\n",
    "    2. Project **non-protected** features onto this basis (in the paper: $ \\mathbf{P}_f\\mathbf{x}_i$  )\n",
    "    3. Complete the solution according to $\\mathbf{r}_j = \\mathbf{x}_i - \\mathbf{P}_f\\mathbf{x}_i$ \n",
    "3. Look at the correlations between **newly aquired non-protected features** and the original protected features. What do you see?\n",
    "    1. Change the fairness penalty term and describe how it changes the correlation structure in data.\n",
    "4. Train a logistic regression model (WITHOUT any penalty) with the **newly aquired non-protected** features. \n",
    "    1. According to the paper - the coefficients of the model (aka betas) that you obtain should be debiased - and you do not have to transform your test set (i.e. project it into unbiased space).\n",
    "    2. Use non-protected features of the test set to evaluate the performance of the model (with fairnes penalty of 1) on different protected subgroups. What do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "## last columns of our data contains the protected features\n",
    "#protected = ...[:,54:] \n",
    "#nonprotected = ...[:,:54]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debias_data(nonprotected, protected):\n",
    "    basis = ...\n",
    "    projection = ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Fair PCA\n",
    "We are going to implement the method from [Efficient fair PCA for fair representation learning](https://deepai.org/publication/efficient-fair-pca-for-fair-representation-learning). Here, we will use dimensionality reduction to remove any existing proxies associated with the protected features\n",
    "1. We are going to work with the pre-processed `X_train` (I'll further refer to it as $X$).\n",
    "2. Create a matrix $Z$ that contains protected features. **Z = [SEX, RAC1P]**. \n",
    "3. Remove mean from each column of $Z$. \n",
    "4. Find orthonormal null-space spanned by $\\mathbf{Z}^T\\mathbf{X}$ - use `scipy.linalg.null_space`. This is our matrix $\\mathbf{R}$ (columns are basis vectors).\n",
    "5. Now we need to find orthonormal eigenvectors of $\\mathbf{R}^T\\mathbf{X}\\mathbf{X}^T\\mathbf{R}$ - use `scipy.linalg.eig` (it outputs both eigenvectors and eigenvalues, and eigenvectors are already sorted based on the eigenvalues). Let's used the first 50 eigenvectors. Now we have matrix $\\mathbf{L}$ (columns are eigenvectors).\n",
    "6. Finaly, we can find the projection matrix $\\mathbf{U} = \\mathbf{R}\\mathbf{L}$.\n",
    "7. Now, we can use $\\mathbf{U}$ to project our data into fair space. $\\mathbf{X}' = \\mathbf{U}^{T}\\mathbf{X}^{T}}$\n",
    "8. Let's see if the projected columns of $\\mathbf{X}'$ are correlated with columns of $\\mathbf{Z}$.\n",
    "9. Use $\\mathbf{X}'$ to train another logistic regression WITHOUT any penalty. \n",
    "10. See how does the model performs on different groups (based on the protected features). Don't forget to use projection matrix $\\mathbf{U}$ to project `X_test` to fair. dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "##### YOUR CODE HERE\n",
    "####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
